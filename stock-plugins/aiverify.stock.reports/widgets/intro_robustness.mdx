Robustness requires that AI systems maintains its level of performance under any circumstances, including potential changes in their operating environment or the presence of other agents (human or artificial) that may interact with the AI system in an adversarial manner.  
 
In this technical test, the tool generates performance metrics when perturbed testing datasets were input to the model. The changes in performance give an idea of the modelâ€™s robustness to potential changes in inputs. Depending on the use case and type of model, users can choose to investigate robustness to adversarial perturbations and/or natural corruptions
